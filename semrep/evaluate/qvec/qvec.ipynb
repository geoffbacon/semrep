{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QVEC\n",
    "\n",
    "This notebook is a replication of Tsvetkov et al. (2015) _Evaluation of Word Vector Representations by Subspace Alignment_, which introduces QVEC. QVEC is an intrinsic evaluation method of word embeddings, measuring the correlation between dimensions of the embeddings and linguistic features. The original code is [available](https://github.com/ytsvetko/qvec), but I'm replicating it for two reasons: i) as a learning exercise and ii) the original implementation looks messy.\n",
    "\n",
    "To implement QVEC, I'm going to need two things:\n",
    "- Gold standard linguistic features\n",
    "- The QVEC model\n",
    "\n",
    "The linguistic features used in the original paper come from SemCor, a WordNet annotated subset of the Brown corpus. This is done in [here](data/evaluation/semcor/semcor.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../../data'\n",
    "tmp_path = '../../tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun.Tops</th>\n",
       "      <th>noun.act</th>\n",
       "      <th>noun.animal</th>\n",
       "      <th>noun.artifact</th>\n",
       "      <th>noun.attribute</th>\n",
       "      <th>noun.body</th>\n",
       "      <th>noun.cognition</th>\n",
       "      <th>noun.communication</th>\n",
       "      <th>noun.event</th>\n",
       "      <th>noun.feeling</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.contact</th>\n",
       "      <th>verb.creation</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abolish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun.Tops  noun.act  noun.animal  noun.artifact  noun.attribute  noun.body  \\\n",
       "0        0.0       0.0          0.0            0.0        0.000000        0.0   \n",
       "1        0.0       0.0          0.0            0.0        0.000000        0.0   \n",
       "2        0.0       0.0          0.0            0.0        0.035714        0.0   \n",
       "3        0.0       0.0          0.0            0.0        0.703704        0.0   \n",
       "4        0.0       0.0          0.0            0.0        0.000000        0.0   \n",
       "\n",
       "   noun.cognition  noun.communication  noun.event  noun.feeling   ...     \\\n",
       "0        0.000000            0.000000         0.0           0.0   ...      \n",
       "1        0.000000            0.272727         0.0           0.0   ...      \n",
       "2        0.000000            0.000000         0.0           0.0   ...      \n",
       "3        0.296296            0.000000         0.0           0.0   ...      \n",
       "4        0.000000            0.000000         0.0           0.0   ...      \n",
       "\n",
       "   verb.contact  verb.creation  verb.emotion  verb.motion  verb.perception  \\\n",
       "0           0.0            0.0           0.0          0.0              0.0   \n",
       "1           0.0            0.0           0.0          0.0              0.0   \n",
       "2           0.0            0.0           0.0          0.0              0.0   \n",
       "3           0.0            0.0           0.0          0.0              0.0   \n",
       "4           0.0            0.0           0.0          0.0              0.0   \n",
       "\n",
       "   verb.possession  verb.social  verb.stative  verb.weather    words  \n",
       "0         0.000000          0.0           0.0           0.0        0  \n",
       "1         0.000000          0.0           0.0           0.0        a  \n",
       "2         0.571429          0.0           0.0           0.0  abandon  \n",
       "3         0.000000          0.0           0.0           0.0  ability  \n",
       "4         0.000000          1.0           0.0           0.0  abolish  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_path = os.path.join(data_path, 'evaluation/semcor/tsvetkov_semcor.csv')\n",
    "subset = pd.read_csv(feature_path, index_col=0)\n",
    "subset.columns = [c.replace('semcor.', '') for c in subset.columns]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QVEC model\n",
    "\n",
    "QVEC finds an alignment between dimensions of learnt word embeddings and dimensions (features) of linguistic features by maximising the cumulative correlation.\n",
    "\n",
    "$N$ is the size of the vocabulary (in common between the embeddings and the linguistic features).\n",
    "\n",
    "$D$ is the dimensionality of the embeddings.\n",
    "\n",
    "$X \\in \\mathbb{R}^{D \\times N}$ is the matrix of embeddings. Note that a word's embedding is a column, rows are individual dimensions.\n",
    "\n",
    "$P$ is the number of linguistic features.\n",
    "\n",
    "$S \\in \\mathbb{R}^{P \\times N}$ is the matrix of linguistic features, created above. Again, each word is a column and rows are individual features.\n",
    "\n",
    "QVEC finds an alignment between the rows of $X$ and the rows of $S$ that maximises the correlation between the aligned rows. Each row of $X$ is aligned to **at most** one row of $S$, but each row of $S$ **may** be aligned to more than one row of $X$.\n",
    "\n",
    "$A \\in \\{0,1\\}^{D \\times P}$ holds the alignments. $x_{ij}$ is 1 if dimension $i$ of $X$ is aligned with linguistic feature $j$.\n",
    "\n",
    "The sum of correlations (which can be arbitrarily large with more dimensions or features) is their measure of the quality of the word embeddings in $X$.\n",
    "\n",
    "$QVEC = \\max_{A|\\sum_{j}a_{ij} \\leq 1}\\sum_{i=1}^{D}\\sum_{j=1}^{P}r(x_i, s_j) \\times a_{ij}$\n",
    "\n",
    "In words, for any possible alignment $A$, subject to the constraint that each embedding dimension is aligned to 0 or 1 linguistic features, sum up the correlations. The sum for the best alignment is the measure of the embeddings.\n",
    "\n",
    "Crucially, this assumes that the dimensions of the embeddings end up encoding linguistic features. The authors justify this by the effectiveness of using word embeddings in linear models in downstream tasks.\n",
    "\n",
    "First things first, transform my linguistic features into the format mentioned above (i.e., the matrix $S$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset.set_index('words', inplace=True)\n",
    "#subset.drop('count_in_semcor', inplace=True, axis=1)\n",
    "subset = subset.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>words</th>\n",
       "      <th>0</th>\n",
       "      <th>a</th>\n",
       "      <th>abandon</th>\n",
       "      <th>ability</th>\n",
       "      <th>abolish</th>\n",
       "      <th>absence</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absorption</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstraction</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>yokuts</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>noun.Tops</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun.act</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun.animal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun.artifact</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun.attribute</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "words             0    a   abandon   ability  abolish  absence  absorb  \\\n",
       "noun.Tops       0.0  0.0  0.000000  0.000000      0.0     0.00     0.0   \n",
       "noun.act        0.0  0.0  0.000000  0.000000      0.0     0.25     0.0   \n",
       "noun.animal     0.0  0.0  0.000000  0.000000      0.0     0.00     0.0   \n",
       "noun.artifact   0.0  0.0  0.000000  0.000000      0.0     0.00     0.0   \n",
       "noun.attribute  0.0  0.0  0.035714  0.703704      0.0     0.00     0.0   \n",
       "\n",
       "words           absorption  abstract  abstraction  ...   yes  yesterday  \\\n",
       "noun.Tops              0.0  0.000000     0.000000  ...   0.0        0.0   \n",
       "noun.act               0.0  0.000000     0.250000  ...   0.0        0.0   \n",
       "noun.animal            0.0  0.000000     0.000000  ...   0.0        0.0   \n",
       "noun.artifact          0.0  0.272727     0.166667  ...   0.0        0.0   \n",
       "noun.attribute         0.0  0.000000     0.000000  ...   0.0        0.0   \n",
       "\n",
       "words           yield  yokuts  york     young  youth   yr  zero  zinc  \n",
       "noun.Tops        0.00     0.0   0.0  0.000000   0.00  0.0   0.0   0.0  \n",
       "noun.act         0.00     0.0   0.0  0.000000   0.00  0.0   0.0   0.0  \n",
       "noun.animal      0.00     0.0   0.0  0.304348   0.00  0.0   0.0   0.0  \n",
       "noun.artifact    0.16     0.0   0.0  0.000000   0.00  0.0   0.0   0.0  \n",
       "noun.attribute   0.00     0.0   0.0  0.000000   0.08  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 4199 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnt word embeddings\n",
    "\n",
    "The original paper trains various different models of varying sizes. At a later stage I could do that, but for now I'm happy with using pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>of</th>\n",
       "      <th>to</th>\n",
       "      <th>and</th>\n",
       "      <th>in</th>\n",
       "      <th>a</th>\n",
       "      <th>\"</th>\n",
       "      <th>'s</th>\n",
       "      <th>...</th>\n",
       "      <th>sigarms</th>\n",
       "      <th>katuna</th>\n",
       "      <th>aqm</th>\n",
       "      <th>1.3775</th>\n",
       "      <th>corythosaurus</th>\n",
       "      <th>chanty</th>\n",
       "      <th>kronik</th>\n",
       "      <th>rolonda</th>\n",
       "      <th>zsombor</th>\n",
       "      <th>sandberger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.41800</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.15164</td>\n",
       "      <td>0.70853</td>\n",
       "      <td>0.680470</td>\n",
       "      <td>0.268180</td>\n",
       "      <td>0.330420</td>\n",
       "      <td>0.21705</td>\n",
       "      <td>0.25769</td>\n",
       "      <td>0.23727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.743970</td>\n",
       "      <td>-0.30016</td>\n",
       "      <td>-1.11670</td>\n",
       "      <td>-0.24171</td>\n",
       "      <td>-0.042672</td>\n",
       "      <td>0.232040</td>\n",
       "      <td>-0.60921</td>\n",
       "      <td>-0.511810</td>\n",
       "      <td>-0.75898</td>\n",
       "      <td>0.072617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.24968</td>\n",
       "      <td>0.236820</td>\n",
       "      <td>0.30177</td>\n",
       "      <td>0.57088</td>\n",
       "      <td>-0.039263</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.249950</td>\n",
       "      <td>0.46515</td>\n",
       "      <td>0.45629</td>\n",
       "      <td>0.40478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082164</td>\n",
       "      <td>-0.80268</td>\n",
       "      <td>0.14057</td>\n",
       "      <td>-0.23367</td>\n",
       "      <td>-0.088106</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>-0.67218</td>\n",
       "      <td>0.058706</td>\n",
       "      <td>-0.47426</td>\n",
       "      <td>-0.513930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.41242</td>\n",
       "      <td>-0.168990</td>\n",
       "      <td>-0.16763</td>\n",
       "      <td>-0.47160</td>\n",
       "      <td>0.301860</td>\n",
       "      <td>-0.278770</td>\n",
       "      <td>-0.608740</td>\n",
       "      <td>-0.46757</td>\n",
       "      <td>-0.76974</td>\n",
       "      <td>-0.20547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.46637</td>\n",
       "      <td>0.36302</td>\n",
       "      <td>0.10672</td>\n",
       "      <td>-0.317240</td>\n",
       "      <td>-0.706990</td>\n",
       "      <td>0.23521</td>\n",
       "      <td>1.091300</td>\n",
       "      <td>0.47370</td>\n",
       "      <td>0.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12170</td>\n",
       "      <td>0.409510</td>\n",
       "      <td>0.17684</td>\n",
       "      <td>0.18048</td>\n",
       "      <td>-0.177920</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>0.109230</td>\n",
       "      <td>0.10082</td>\n",
       "      <td>-0.37679</td>\n",
       "      <td>0.58805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>-0.29822</td>\n",
       "      <td>-0.13836</td>\n",
       "      <td>-1.60230</td>\n",
       "      <td>-0.252090</td>\n",
       "      <td>-0.045465</td>\n",
       "      <td>-0.11195</td>\n",
       "      <td>-0.551630</td>\n",
       "      <td>0.77250</td>\n",
       "      <td>-0.522020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.34527</td>\n",
       "      <td>0.638120</td>\n",
       "      <td>0.31719</td>\n",
       "      <td>0.54449</td>\n",
       "      <td>0.429620</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.036372</td>\n",
       "      <td>1.01350</td>\n",
       "      <td>0.59272</td>\n",
       "      <td>0.65533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422550</td>\n",
       "      <td>-1.03200</td>\n",
       "      <td>-1.47970</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>-0.268510</td>\n",
       "      <td>0.139890</td>\n",
       "      <td>-0.46094</td>\n",
       "      <td>-0.102490</td>\n",
       "      <td>-0.78064</td>\n",
       "      <td>-0.355340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      the         ,        .       of        to       and        in        a  \\\n",
       "1  0.41800  0.013441  0.15164  0.70853  0.680470  0.268180  0.330420  0.21705   \n",
       "2  0.24968  0.236820  0.30177  0.57088 -0.039263  0.143460  0.249950  0.46515   \n",
       "3 -0.41242 -0.168990 -0.16763 -0.47160  0.301860 -0.278770 -0.608740 -0.46757   \n",
       "4  0.12170  0.409510  0.17684  0.18048 -0.177920  0.016257  0.109230  0.10082   \n",
       "5  0.34527  0.638120  0.31719  0.54449  0.429620  0.113840  0.036372  1.01350   \n",
       "\n",
       "0        \"       's     ...       sigarms   katuna      aqm   1.3775  \\\n",
       "1  0.25769  0.23727     ...     -0.743970 -0.30016 -1.11670 -0.24171   \n",
       "2  0.45629  0.40478     ...      0.082164 -0.80268  0.14057 -0.23367   \n",
       "3 -0.76974 -0.20547     ...     -0.009147 -0.46637  0.36302  0.10672   \n",
       "4 -0.37679  0.58805     ...      0.412900 -0.29822 -0.13836 -1.60230   \n",
       "5  0.59272  0.65533     ...     -0.422550 -1.03200 -1.47970  0.12440   \n",
       "\n",
       "0  corythosaurus    chanty   kronik   rolonda  zsombor  sandberger  \n",
       "1      -0.042672  0.232040 -0.60921 -0.511810 -0.75898    0.072617  \n",
       "2      -0.088106  0.025672 -0.67218  0.058706 -0.47426   -0.513930  \n",
       "3      -0.317240 -0.706990  0.23521  1.091300  0.47370    0.472800  \n",
       "4      -0.252090 -0.045465 -0.11195 -0.551630  0.77250   -0.522020  \n",
       "5      -0.268510  0.139890 -0.46094 -0.102490 -0.78064   -0.355340  \n",
       "\n",
       "[5 rows x 400000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 50\n",
    "fname = 'embeddings/glove.6B.{}d.txt'.format(size)\n",
    "embedding_path = os.path.join(data_path, fname)\n",
    "embeddings = pd.read_csv(embedding_path, sep=' ', header=None, index_col=0, quoting=csv.QUOTE_NONE).T\n",
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_words = embeddings.columns.intersection(subset.columns)\n",
    "embeddings = embeddings[common_words]\n",
    "fname = os.path.join(tmp_path, 'glove_embeddings.csv')\n",
    "embeddings.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python variables S and X refer to $S$ and $X$ exactly as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = subset[common_words]\n",
    "X = embeddings[common_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want the correlation between the rows of S and the rows of X. This may not be the easiest way to do it but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations = pd.DataFrame({i:X.corrwith(S.iloc[i], axis=1) for i in range(len(S))})\n",
    "correlations.columns = S.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row of this correlation matrix (i.e. for each of the dimenions of the embeddings), we want the linguistic feature that it is most correlated with. We also get the value of that correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.073672\n",
       "2    0.114031\n",
       "3    0.128516\n",
       "4    0.103564\n",
       "5    0.207579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignments = correlations.idxmax(axis=1)\n",
    "correlations.max(axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the embeddings relative to the linguistic features is the sum of the maximum correlations. Note how this value depends on how many dimensions in the embeddings there are. For 300 dimension vectors trained (by them) from GloVe, the authors get 34.4, while I get 32.4. Note that our linguistic features are still different, so the fact that the discrepancy here is not too big is encouraging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0863957435227896"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvec = correlations.max(axis=1).sum()\n",
    "qvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really need it, but just to be explicit let's get the matrix $A$ of alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun.Tops</th>\n",
       "      <th>noun.act</th>\n",
       "      <th>noun.animal</th>\n",
       "      <th>noun.artifact</th>\n",
       "      <th>noun.attribute</th>\n",
       "      <th>noun.body</th>\n",
       "      <th>noun.cognition</th>\n",
       "      <th>noun.communication</th>\n",
       "      <th>noun.event</th>\n",
       "      <th>noun.feeling</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.consumption</th>\n",
       "      <th>verb.contact</th>\n",
       "      <th>verb.creation</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun.Tops  noun.act  noun.animal  noun.artifact  noun.attribute  noun.body  \\\n",
       "0          0         0            0              0               0          0   \n",
       "1          0         0            0              0               0          0   \n",
       "2          0         0            0              0               0          0   \n",
       "3          0         0            0              0               0          0   \n",
       "4          0         0            0              0               0          0   \n",
       "\n",
       "   noun.cognition  noun.communication  noun.event  noun.feeling      ...       \\\n",
       "0               0                   0           0             0      ...        \n",
       "1               0                   0           0             0      ...        \n",
       "2               0                   1           0             0      ...        \n",
       "3               0                   0           0             0      ...        \n",
       "4               0                   0           0             0      ...        \n",
       "\n",
       "   verb.consumption  verb.contact  verb.creation  verb.emotion  verb.motion  \\\n",
       "0                 0             0              0             0            0   \n",
       "1                 0             0              0             0            0   \n",
       "2                 0             0              0             0            0   \n",
       "3                 0             0              0             0            0   \n",
       "4                 0             0              0             0            0   \n",
       "\n",
       "   verb.perception  verb.possession  verb.social  verb.stative  verb.weather  \n",
       "0                0                0            0             0             0  \n",
       "1                0                0            0             0             0  \n",
       "2                0                0            0             0             0  \n",
       "3                0                1            0             0             0  \n",
       "4                0                0            0             0             0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = pd.DataFrame(0, index=range(len(X)), columns=S.index)\n",
    "for dim, feat in alignments.iteritems():\n",
    "    A[feat][dim] = 1\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The rest of the paper is a series of experiments training large models and evaluating them on both instrinic and extrinsic tasks, including QVEC. I'm not going to replicate that here, but the QVEC implementation is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Correlation Analysis\n",
    "\n",
    "In a follow-up 2016 paper, a subset of the original authors introduce QVEC-CCA. It's really just QVEC except instead of summing the highest row-wise correlations, they use canonical correlation analysis. I didn't know what that was, but after reading a bit I have a reasonable grasp of it. I'm going to replicate that 2016 paper, or at least the most important part of it which is the use of CCA. Note that the other new thing in the 2016 paper is the use of syntactic features, in addition to semantic, which I won't do right now.\n",
    "\n",
    "Scikit-learn has an implementation of CCA. It took me a while to figure out what are the learnt parameters that I want, and I'm only 80% confident I have it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "cca = CCA(n_components=1)\n",
    "cca = cca.fit(X.T, S.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the linear combinations I want are stored in the `x_weights_` and `y_weights_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.73791464]), array([ 0.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.dot(X.T, cca.x_weights_)\n",
    "b = np.dot(S.T, cca.y_weights_)\n",
    "stats.pearsonr(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Succint implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qvec(features, embeddings):\n",
    "    \"\"\"\n",
    "    Returns correlations between columns of `features` and `embeddings`.\n",
    "    \n",
    "    The aligned feature is the one with the highest correlation.\n",
    "    The qvec score is the sum of correlations of aligned features.\n",
    "    \"\"\"\n",
    "    common_words = embeddings.columns.intersection(subset.columns)\n",
    "    S = features[common_words]\n",
    "    X = embeddings[common_words]\n",
    "    correlations = pd.DataFrame({i:X.corrwith(S.iloc[i], axis=1) for i in range(len(S))})\n",
    "    correlations.columns = S.index\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun.Tops</th>\n",
       "      <th>noun.act</th>\n",
       "      <th>noun.animal</th>\n",
       "      <th>noun.artifact</th>\n",
       "      <th>noun.attribute</th>\n",
       "      <th>noun.body</th>\n",
       "      <th>noun.cognition</th>\n",
       "      <th>noun.communication</th>\n",
       "      <th>noun.event</th>\n",
       "      <th>noun.feeling</th>\n",
       "      <th>...</th>\n",
       "      <th>verb.consumption</th>\n",
       "      <th>verb.contact</th>\n",
       "      <th>verb.creation</th>\n",
       "      <th>verb.emotion</th>\n",
       "      <th>verb.motion</th>\n",
       "      <th>verb.perception</th>\n",
       "      <th>verb.possession</th>\n",
       "      <th>verb.social</th>\n",
       "      <th>verb.stative</th>\n",
       "      <th>verb.weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>0.056525</td>\n",
       "      <td>-0.037133</td>\n",
       "      <td>-0.021099</td>\n",
       "      <td>0.042961</td>\n",
       "      <td>-0.037595</td>\n",
       "      <td>-0.067074</td>\n",
       "      <td>0.056121</td>\n",
       "      <td>-0.020713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034959</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>0.061470</td>\n",
       "      <td>0.014180</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.047905</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.066336</td>\n",
       "      <td>0.009226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010114</td>\n",
       "      <td>-0.036833</td>\n",
       "      <td>-0.073421</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.089190</td>\n",
       "      <td>-0.024908</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.114031</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042820</td>\n",
       "      <td>-0.125930</td>\n",
       "      <td>-0.046195</td>\n",
       "      <td>-0.018379</td>\n",
       "      <td>-0.077600</td>\n",
       "      <td>-0.043725</td>\n",
       "      <td>-0.075241</td>\n",
       "      <td>-0.118294</td>\n",
       "      <td>-0.023466</td>\n",
       "      <td>-0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.017465</td>\n",
       "      <td>-0.113412</td>\n",
       "      <td>-0.071950</td>\n",
       "      <td>0.107044</td>\n",
       "      <td>-0.040075</td>\n",
       "      <td>-0.040329</td>\n",
       "      <td>-0.123985</td>\n",
       "      <td>-0.154424</td>\n",
       "      <td>-0.018798</td>\n",
       "      <td>-0.036100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025986</td>\n",
       "      <td>0.109754</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.024162</td>\n",
       "      <td>0.075199</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.128516</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.030984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046736</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>0.016308</td>\n",
       "      <td>0.039305</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>-0.013023</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.046805</td>\n",
       "      <td>-0.046602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045769</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>-0.033100</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>-0.037468</td>\n",
       "      <td>-0.047789</td>\n",
       "      <td>-0.017277</td>\n",
       "      <td>-0.012592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.076649</td>\n",
       "      <td>-0.096512</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>-0.025811</td>\n",
       "      <td>0.107881</td>\n",
       "      <td>-0.032195</td>\n",
       "      <td>0.101387</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>-0.041974</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>-0.034706</td>\n",
       "      <td>-0.035682</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>-0.119434</td>\n",
       "      <td>-0.000516</td>\n",
       "      <td>0.037925</td>\n",
       "      <td>-0.028063</td>\n",
       "      <td>-0.016718</td>\n",
       "      <td>-0.069846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun.Tops  noun.act  noun.animal  noun.artifact  noun.attribute  noun.body  \\\n",
       "1   0.040100  0.026092     0.056525      -0.037133       -0.021099   0.042961   \n",
       "2   0.010114 -0.036833    -0.073421       0.031081        0.089190  -0.024908   \n",
       "3  -0.017465 -0.113412    -0.071950       0.107044       -0.040075  -0.040329   \n",
       "4   0.046736  0.028456     0.016308       0.039305        0.007064  -0.020841   \n",
       "5   0.076649 -0.096512     0.021287      -0.025811        0.107881  -0.032195   \n",
       "\n",
       "   noun.cognition  noun.communication  noun.event  noun.feeling      ...       \\\n",
       "1       -0.037595           -0.067074    0.056121     -0.020713      ...        \n",
       "2        0.062203            0.114031    0.003696      0.060540      ...        \n",
       "3       -0.123985           -0.154424   -0.018798     -0.036100      ...        \n",
       "4       -0.013023            0.024967    0.046805     -0.046602      ...        \n",
       "5        0.101387            0.021477   -0.041974      0.032073      ...        \n",
       "\n",
       "   verb.consumption  verb.contact  verb.creation  verb.emotion  verb.motion  \\\n",
       "1          0.034959     -0.045302       0.061470      0.014180     0.036282   \n",
       "2         -0.042820     -0.125930      -0.046195     -0.018379    -0.077600   \n",
       "3          0.025986      0.109754       0.011967      0.024162     0.075199   \n",
       "4         -0.045769     -0.011350      -0.033100     -0.054945    -0.064516   \n",
       "5          0.000242     -0.034706      -0.035682      0.005210    -0.119434   \n",
       "\n",
       "   verb.perception  verb.possession  verb.social  verb.stative  verb.weather  \n",
       "1         0.047905         0.056783     0.045944      0.066336      0.009226  \n",
       "2        -0.043725        -0.075241    -0.118294     -0.023466     -0.000403  \n",
       "3         0.021415         0.128516     0.039837      0.026042      0.030984  \n",
       "4        -0.007210        -0.037468    -0.047789     -0.017277     -0.012592  \n",
       "5        -0.000516         0.037925    -0.028063     -0.016718     -0.069846  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvec(subset, embeddings).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
